from transformers import GPT2Tokenizer, GPT2LMHeadModel

# Load the tokenizer and model
tokenizer = GPT2Tokenizer.from_pretrained("path_to_save_model")  # Replace "path_to_save_model" with the actual path
model = GPT2LMHeadModel.from_pretrained("path_to_save_model")

# Set the model to evaluation mode
model.eval()

# Example usage: Generate text
input_text = "Once upon a time"
input_ids = tokenizer(input_text, return_tensors="pt").input_ids
output_ids = model.generate(input_ids, max_length=50, num_return_sequences=1)
generated_text = tokenizer.decode(output_ids[0], skip_special_tokens=True)

print("Generated text:", generated_text)
